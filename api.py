# -*- coding: utf-8 -*-
"""API.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OegP7tNa3-oabXKZz93UUMXHVjANeaqv
"""

!curl -X POST -d '{"includedTypes": ["restaurant"],"maxResultCount": 10,"locationRestriction": {"circle": {"center": {"latitude": 37.7937,"longitude": -122.3965},"radius": 500.0}}}' -H 'Content-Type: application/json' -H "X-Goog-Api-Key: AIzaSyBQQZ0nducO31cGjLUnQaM5SP4fCNda3pw" -H "X-Goog-FieldMask: places.displayName,places.reviews" https://places.googleapis.com/v1/places:searchNearby

pip install pandas

import pandas as pd
import os

df = pd.read_excel('/content/movie_locations_with_names.xlsx')

df

# Function to write reviews to the file
def write_reviews_to_file(file, place_name, reviews, lat, lon):
    file.write(f"\nReviews for {place_name} (Coordinates: {lat}, {lon}):\n")
    file.write("="*50 + "\n")
    for review in reviews:
        file.write(f"Rating: {review.get('rating', 'N/A')}\n")
        file.write(f"Text: {review.get('text', {}).get('text', 'No text')}\n")
        file.write(f"Author: {review.get('authorAttribution', {}).get('displayName', 'Anonymous')}\n")
        file.write(f"Published: {review.get('publishTime', 'N/A')}\n")
        file.write("\n---\n\n")

import requests
import json
from datetime import datetime

url = "https://places.googleapis.com/v1/places:searchNearby"
api_key = "AIzaSyBQQZ0nducO31cGjLUnQaM5SP4fCNda3pw"

headers = {
    "Content-Type": "application/json",
    "X-Goog-Api-Key": api_key,
    "X-Goog-FieldMask": "places.displayName,places.reviews"
}

# Create a timestamp for the filename
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
filename = f"all_reviews_{timestamp}.txt"

# Loop through each row in the DataFrame
with open(filename, 'w', encoding='utf-8') as file:
    for index, row in df.iterrows():
        latitude = row['Latitude']
        longitude = row['Longitude']

        data = {
            "includedTypes": ["tourist_attraction"],
            "maxResultCount": 5,  # Request only 5 places
            "locationRestriction": {
                "circle": {
                    "center": {
                        "latitude": latitude,
                        "longitude": longitude
                    },
                    "radius": 500.0
                }
            }
        }

        response = requests.post(url, headers=headers, data=json.dumps(data))

        print(f"For coordinates: {latitude}, {longitude}")
        print(f"Status code: {response.status_code}")

        if response.status_code == 200:
            result = response.json()
            places = result.get('places', [])

            for place in places:
                place_name = place.get('displayName', {}).get('text', 'Unnamed Place')
                reviews = place.get('reviews', [])
                if reviews:
                    write_reviews_to_file(file, place_name, reviews, latitude, longitude)
                    print(f"Saved reviews for {place_name}")
                else:
                    print(f"No reviews found for {place_name}")
        else:
            print(f"Error: {response.text}")

        print("\n" + "="*50 + "\n")  # Separator between results

print(f"All reviews have been saved to {filename}")

for place in result['places']:
    print(place['displayName']['text'])
    print((place['reviews']))

import requests
import json
import pandas as pd
from datetime import datetime

# Assuming you've already loaded your DataFrame
# df = pd.read_excel('your_file.xlsx')

url = "https://places.googleapis.com/v1/places:searchNearby"
api_key = "AIzaSyBQQZ0nducO31cGjLUnQaM5SP4fCNda3pw"

headers = {
    "Content-Type": "application/json",
    "X-Goog-Api-Key": api_key,
    "X-Goog-FieldMask": "places.displayName,places.reviews"
}

# Create a list to store review data
review_data = []

for index, row in df.iterrows():
    latitude = row['Latitude']
    longitude = row['Longitude']

    data = {
        "includedTypes": ["tourist_attraction"],
        "maxResultCount": 5,
        "locationRestriction": {
            "circle": {
                "center": {
                    "latitude": latitude,
                    "longitude": longitude
                },
                "radius": 500.0
            }
        }
    }

    response = requests.post(url, headers=headers, data=json.dumps(data))

    print(f"For coordinates: {latitude}, {longitude}")
    print(f"Status code: {response.status_code}")

    if response.status_code == 200:
        result = response.json()
        places = result.get('places', [])

        for place in places:
            place_name = place.get('displayName', {}).get('text', 'Unnamed Place')
            reviews = place.get('reviews', [])
            if reviews:
                for review in reviews:
                    rating = review.get('rating', 'N/A')
                    review_text = review.get('text', {}).get('text', 'No text')

                    # Add review data to the list
                    review_data.append({
                        'review_text': review_text,
                        'longitude': longitude,
                        'latitude': latitude,
                        'place_name': place_name,
                        'rating': rating
                    })

                print(f"Processed reviews for {place_name}")
            else:
                print(f"No reviews found for {place_name}")
    else:
        print(f"Error: {response.text}")

    print("\n" + "="*50 + "\n")  # Separator between results

# Create the review_analysis DataFrame
review_analysis = pd.DataFrame(review_data)

# Save the review_analysis DataFrame to a CSV file
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
csv_filename = f"review_analysis_{timestamp}.csv"
review_analysis.to_csv(csv_filename, index=False)
print(f"Review analysis data has been saved to {csv_filename}")

# Display the first few rows and basic info of the DataFrame
print(review_analysis.head())
print("\nDataFrame Info:")
print(review_analysis.info())

review_analysis

!pip install transformers

from transformers import pipeline
import pandas as pd
import os

classifier = pipeline("text-classification", model = 'bhadresh-savani/distilbert-base-uncased-emotion', return_all_scores = True)

review_analysis['label_sadness'],review_analysis['label_joy'], review_analysis['label_love'], review_analysis['label_anger'], review_analysis['label_fear'], review_analysis['label_surprise'] = None, None, None, None, None, None

for i in range(len(review_analysis)):
    try:
      prediction = classifier (review_analysis['review_text'][i],)
      review_analysis['label_sadness'][i] = prediction[0][0]['score']
      review_analysis['label_joy'][i] = prediction[0][1]['score']
      review_analysis['label_love'][i] = prediction[0][2]['score']
      review_analysis['label_anger'][i] = prediction[0][3]['score']
      review_analysis['label_fear'][i] = prediction[0][4]['score']
      review_analysis['label_surprise'][i] = prediction[0][5]['score']
    except RuntimeError:
      review_analysis = review_analysis.drop(i)